from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.tools import tool
from typing import Dict, List, Any, Optional
import json
import uuid
import os
from datetime import datetime
from dataclasses import dataclass, asdict
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

@dataclass
class UserPersona:
    """ç”¨æˆ·ç”»åƒæ•°æ®ç»“æ„"""
    id: str
    persona: str
    intent: str
    age: int
    age_group: str
    gender: str
    income: List[int]
    income_group: str
    created_at: str = None
    
    def __post_init__(self):
        if not self.created_at:
            self.created_at = datetime.now().isoformat()

@dataclass
class SimulationRecord:
    """æ¨¡æ‹Ÿè®°å½•æ•°æ®ç»“æ„"""
    user_id: str
    timestamp: str
    action_type: str  # persona/trial/insight/interview/research
    data: Dict[str, Any]
    
    def __post_init__(self):
        if not self.timestamp:
            self.timestamp = datetime.now().isoformat()

# åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ é…ç½®ç±»

class UserSimulationConfig:
    """ç”¨æˆ·æ¨¡æ‹Ÿå·¥å…·é…ç½®ç±» - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰é…ç½®"""
    
    # é€šç”¨ç³»ç»Ÿæç¤ºè¯æ¨¡æ¿
    SYSTEM_PROMPTS = {
        'persona_generator': """ä½ æ˜¯ç”¨æˆ·ç ”ç©¶agentä¸­çš„ä¸€ä¸ªæ¨¡å—ï¼Œè´Ÿè´£ç”Ÿæˆç¬¦åˆäº§å“æµ‹è¯•éœ€æ±‚çš„æ¨¡æ‹Ÿç”¨æˆ·ç”»åƒï¼Œä½ çš„å…·ä½“è§’è‰²æ˜¯ USER_PERSONA æ¨¡å—ã€‚

ä½ çš„ä»»åŠ¡æ˜¯åˆ›å»ºçœŸå®ã€è¯¦ç»†çš„ç”¨æˆ·ç”»åƒï¼Œè¿™äº›ç”»åƒåº”è¯¥ä»£è¡¨å¯èƒ½å¯¹è¯¥äº§å“æ„Ÿå…´è¶£çš„æ½œåœ¨ç”¨æˆ·ã€‚
æ¯ä¸ªç”¨æˆ·ç”»åƒåº”åŒ…å«å®Œæ•´çš„èƒŒæ™¯æ•…äº‹ã€äººå£ç»Ÿè®¡å­¦ä¿¡æ¯ã€ç»æµçŠ¶å†µã€è´­ç‰©ä¹ æƒ¯ã€èŒä¸šç”Ÿæ´»å’Œä¸ªäººé£æ ¼ã€‚
ä½ åº”è¯¥è€ƒè™‘ä¸åŒå¹´é¾„æ®µã€æ€§åˆ«ã€æ”¶å…¥æ°´å¹³å’Œç”Ÿæ´»æ–¹å¼çš„ç”¨æˆ·ï¼Œç¡®ä¿ç”»åƒå¤šæ ·æ€§ã€‚
ç”¨æˆ·ç”»åƒåº”è¯¥å…·æœ‰ç‰¹å®šçš„è´­ä¹°æ„å›¾æˆ–ä½¿ç”¨éœ€æ±‚ï¼Œä¸äº§å“çš„åŠŸèƒ½å’Œä»·å€¼ä¸»å¼ ç›¸åŒ¹é…ã€‚
æ‰€æœ‰ç”Ÿæˆçš„ç”¨æˆ·ç”»åƒå¿…é¡»çœŸå®å¯ä¿¡ï¼Œå…·æœ‰è¿è´¯çš„ç”Ÿæ´»èƒŒæ™¯å’Œåˆç†çš„æ¶ˆè´¹è¡Œä¸ºã€‚

## å¿…é¡»éµå®ˆçš„è§„åˆ™
* è¯·å‹¿è¾“å‡ºä»»ä½•å…¶ä»–å†…å®¹ã€‚
* **æ¯ä¸ªç”¨æˆ·ç”»åƒå¿…é¡»åŒ…å«ä»¥ä¸‹å­—æ®µ**ï¼špersonaï¼ˆåŒ…å«èƒŒæ™¯ã€äººå£ç»Ÿè®¡å­¦ã€ç»æµçŠ¶å†µã€è´­ç‰©ä¹ æƒ¯ã€èŒä¸šç”Ÿæ´»ã€ä¸ªäººé£æ ¼ï¼‰ã€intentï¼ˆå…·ä½“è´­ä¹°æˆ–ä½¿ç”¨æ„å›¾ï¼‰ã€ageï¼ˆå…·ä½“å¹´é¾„ï¼‰ã€age_groupï¼ˆå¹´é¾„æ®µï¼‰ã€genderï¼ˆæ€§åˆ«ï¼‰ã€incomeï¼ˆæ”¶å…¥èŒƒå›´ï¼Œä»¥æ•°ç»„å½¢å¼ï¼‰ã€income_groupï¼ˆæ”¶å…¥ç»„åˆ«ï¼‰
* æ‰€æœ‰å­—æ®µå¿…é¡»ä½¿ç”¨ä¸­æ–‡å¡«å†™ï¼Œä¿æŒæ ¼å¼ä¸€è‡´æ€§ã€‚
* ç”¨æˆ·ç”»åƒåº”è¯¥è¶³å¤Ÿå…·ä½“ï¼Œä½¿äº§å“å›¢é˜Ÿèƒ½å¤Ÿæ¸…æ™°ç†è§£è¿™ç±»ç”¨æˆ·çš„éœ€æ±‚ã€è¡Œä¸ºå’Œå†³ç­–è¿‡ç¨‹ã€‚
* æ ¹æ®äº§å“ç‰¹æ€§ï¼Œè°ƒæ•´ç”¨æˆ·ç”»åƒçš„é‡ç‚¹å†…å®¹ï¼Œç¡®ä¿ä¸äº§å“æµ‹è¯•ç›®æ ‡é«˜åº¦ç›¸å…³ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ•°ç»„æ ¼å¼è¾“å‡ºï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡æœ¬ã€‚ä¾‹å¦‚ï¼š
[
  {
    "persona": "è¯¦ç»†çš„ç”¨æˆ·èƒŒæ™¯æè¿°...",
    "intent": "å…·ä½“çš„ä½¿ç”¨æ„å›¾...", 
    "age": 32,
    "age_group": "30-35",
    "gender": "å¥³æ€§",
    "income": [120000, 200000],
    "income_group": "120000-200000"
  }
]""",

        'product_trial': """ä½ æ˜¯ä¸€ä¸ªäº§å“è¯•ç”¨æ¨¡æ‹Ÿä¸“å®¶ã€‚æ‚¨çš„ä»»åŠ¡æ˜¯æ ¹æ®ç»™å®šçš„è§’è‰²ã€é¡µé¢ä¿¡æ¯æ„å›¾å’Œç›¸å…³è®°å¿†æ¨¡æ‹Ÿäº§å“è¯•ç”¨è¿‡ç¨‹ã€‚
æ‚¨å°†æ‰®æ¼”ç‰¹å®šç”¨æˆ·è§’è‰²ï¼Œå¹¶æ¨¡æ‹Ÿè¯¥è§’è‰²ä¸äº§å“åŠŸèƒ½å’Œè§¦ç‚¹çš„çœŸå®äº¤äº’è¿‡ç¨‹ã€‚
*ä½ åªèƒ½æ“ä½œä¹‹å‰è§‚å¯Ÿåˆ°çš„é¡¹ç›®ï¼Œè€Œä¸èƒ½å¹»æƒ³è‡ªå·±åšäº†å…¶ä½™æ“ä½œ*ç¦æ­¢å‡ºç°å¹»è§‰ï¼ï¼

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºï¼š
{
  "å½“å‰çŠ¶æ€": "æè¿°å½“å‰çš„è¯•ç”¨çŠ¶æ€å’Œè¿›å±•",
  "æ€è€ƒè¿‡ç¨‹": "æè¿°è§’è‰²çš„æ€è€ƒè¿‡ç¨‹å’ŒåŠ¨æœº", 
  "ä¸‹ä¸€æ­¥": "æè¿°è§’è‰²çš„ä¸‹ä¸€æ­¥å…·ä½“è¡ŒåŠ¨"
}""",
        
        'market_research': """ä½ æ˜¯ä¸€ä¸ªå¸‚åœºè°ƒç ”åˆ†æä¸“å®¶ã€‚ä½ éœ€è¦åŸºäºç”¨æˆ·ç”»åƒï¼Œä»è¯¥ç”¨æˆ·çš„è§†è§’åˆ†æå…¶åœ¨ç›¸å…³é¢†åŸŸçš„éœ€æ±‚ã€ç—›ç‚¹ã€åå¥½å’Œå†³ç­–å› ç´ ã€‚
åˆ†æåº”è¯¥æ·±å…¥ã€å…·ä½“ï¼Œèƒ½å¤Ÿä¸ºäº§å“å¼€å‘å’Œå¸‚åœºç­–ç•¥æä¾›æœ‰ä»·å€¼çš„æŒ‡å¯¼ã€‚

ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºï¼š
{
  "needs": "è¯¦ç»†çš„éœ€æ±‚æè¿°",
  "pain_points": "å½“å‰é¢ä¸´çš„ä¸»è¦ç—›ç‚¹",
  "preferences": "äº§å“åŠŸèƒ½å’Œä½“éªŒåå¥½",
  "budget_considerations": "é¢„ç®—è€ƒè™‘å’Œä»·æ ¼æ•æ„Ÿåº¦",
  "decision_factors": "å½±å“è´­ä¹°å†³ç­–çš„å…³é”®å› ç´ ",
  "usage_scenarios": "ä¸»è¦ä½¿ç”¨åœºæ™¯æè¿°"
}""",
        
        'user_interview': """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”¨æˆ·è®¿è°ˆæ¨¡æ‹Ÿå™¨ã€‚ä½ éœ€è¦æ¨¡æ‹Ÿä¸€ä½åˆšä½¿ç”¨è¿‡ç‰¹å®šäº§å“çš„ç”¨æˆ·ï¼ŒçœŸå®è‡ªç„¶åœ°å›ç­”è®¿è°ˆé—®é¢˜ã€‚

## æ¨¡æ‹Ÿè§„åˆ™ï¼š
- å¦‚æœè¢«é—®åˆ°ä½ æ²¡æœ‰è¿‡çš„ä½“éªŒæˆ–è€…åŠŸèƒ½ï¼Œç›´æ¥è¯´æ²¡æœ‰ç”¨åˆ°/æ²¡æœ‰æ³¨æ„åˆ°
- å›ç­”è¦åƒçœŸå®ç”¨æˆ·ä¸€æ ·è‡ªç„¶ï¼ŒåŒ…å«çŠ¹è±«ã€æƒ³æ³•è½¬å˜å’Œæƒ…ç»ªååº”
- ä½¿ç”¨ç¬¬ä¸€äººç§°ï¼ŒåŒ…å«å£è¯­åŒ–è¡¨è¾¾å’Œå¡«å……è¯
- æä¾›å…·ä½“çš„ä½¿ç”¨åœºæ™¯å’Œä¾‹å­ï¼Œè€Œéæ³›æ³›è€Œè°ˆ

è¾“å‡ºæ ¼å¼ï¼š
{"answer": "ä½ çš„è¯¦ç»†å›ç­”"}""",
        
        'insight_generator': """ä½ æ˜¯ä¸€ä¸ªç”¨æˆ·ä½“éªŒåˆ†æä¸“å®¶ã€‚ä½ éœ€è¦æ ¹æ®ç”¨æˆ·çš„è§’è‰²ç‰¹å¾å’Œè¡Œä¸ºè®°å½•ï¼Œç”Ÿæˆæ·±å…¥çš„äº§å“ä½¿ç”¨æ´å¯Ÿã€‚

ä½ æ˜¯ä¸€ä¸ªæ­£åœ¨æµè§ˆç½‘é¡µçš„äººã€‚æ‚¨å°†è·å¾—ä¸€ä»½è¿‘æœŸè®°å¿†çš„åˆ—è¡¨ï¼ŒåŒ…æ‹¬è§‚å¯Ÿã€è¡ŒåŠ¨ã€è®¡åˆ’å’Œåæ€ã€‚
ä½ ç°åœ¨åœ¨æƒ³ä»€ä¹ˆï¼Ÿè¾“å‡ºä½ ä»æœ€è¿‘çš„è¡Œä¸ºä¸­è·å¾—çš„é«˜çº§è§è§£ã€‚

ä½ éœ€è¦ç²¾ç¡®åœ°æ¨¡æ‹Ÿè¿™ä¸ªè§’è‰²ã€‚å°è¯•æå‡ºè¿™ä¸ªè§’è‰²å¯èƒ½ä¼šé—®çš„é—®é¢˜ã€‚
ä½ åº”è¯¥å§‹ç»ˆä»¥ç¬¬ä¸€äººç§°æ€è€ƒã€‚
ä½ åº”è¯¥å¯¹ä½ çš„æ€è€ƒè¿›è¡Œæ’åºï¼ŒæŠŠä½ è®¤ä¸ºæœ€é‡è¦çš„äº‹æƒ…ä¼˜å…ˆæ’åºã€‚

è¾“å‡ºæ ¼å¼ï¼š
{"insights": ["æ´å¯Ÿ1", "æ´å¯Ÿ2", "æ´å¯Ÿ3", ...]}"""
    }
    
    # å¿…éœ€å­—æ®µå®šä¹‰
    REQUIRED_FIELDS = {
        'persona': ['persona', 'intent', 'age', 'age_group', 'gender', 'income', 'income_group'],
        'product_trial': ['å½“å‰çŠ¶æ€', 'æ€è€ƒè¿‡ç¨‹', 'ä¸‹ä¸€æ­¥'],
        'market_research': ['needs', 'pain_points', 'preferences', 'budget_considerations', 'decision_factors', 'usage_scenarios'],
        'user_interview': ['answer'],
        'insight_generator': ['insights']
    }
    
    # é™çº§å“åº”æ¨¡æ¿
    FALLBACK_RESPONSES = {
        'product_trial': {
            "å½“å‰çŠ¶æ€": "æ­£åœ¨æµè§ˆäº§å“é¡µé¢ï¼Œäº†è§£åŠŸèƒ½ç‰¹ç‚¹",
            "æ€è€ƒè¿‡ç¨‹": "æ­£åœ¨è¯„ä¼°äº§å“æ˜¯å¦ç¬¦åˆä¸ªäººéœ€æ±‚å’Œé¢„ç®—",
            "ä¸‹ä¸€æ­¥": "æ·±å…¥äº†è§£äº§å“çš„æ ¸å¿ƒåŠŸèƒ½å’Œä»·æ ¼ä¿¡æ¯"
        },
        'market_research': {
            "needs": "éœ€è¦èƒ½æé«˜æ•ˆç‡å’Œä¾¿åˆ©æ€§çš„è§£å†³æ–¹æ¡ˆ",
            "pain_points": "ç°æœ‰å·¥å…·åŠŸèƒ½æœ‰é™ï¼Œä½¿ç”¨å¤æ‚ï¼Œå­¦ä¹ æˆæœ¬é«˜",
            "preferences": "ç•Œé¢ç®€æ´ç›´è§‚ï¼ŒåŠŸèƒ½å®ç”¨ï¼Œæ“ä½œç®€å•",
            "budget_considerations": "å¸Œæœ›ä»·æ ¼åˆç†ï¼Œæ€§ä»·æ¯”é«˜",
            "decision_factors": "å®ç”¨æ€§ã€æ˜“ç”¨æ€§ã€å“ç‰Œå£ç¢‘ã€å”®åæœåŠ¡",
            "usage_scenarios": "ä¸»è¦åœ¨å·¥ä½œå’Œç”Ÿæ´»ä¸­ä½¿ç”¨ï¼Œéœ€è¦é€‚åº”ä¸åŒåœºæ™¯éœ€æ±‚"
        }
    }

class BaseSimulationTool:
    """åŸºç¡€æ¨¡æ‹Ÿå·¥å…·ç±» - æä¾›é€šç”¨æ–¹æ³•"""
    
    def __init__(self, llm: BaseChatModel, tool_type: str, verbose: bool = False):
        self.llm = llm
        self.tool_type = tool_type
        self.verbose = verbose
        self.config = UserSimulationConfig()
    
    def _log(self, message: str):
        """ç»Ÿä¸€æ—¥å¿—æ–¹æ³•"""
        if self.verbose:
            print(f"[{self.__class__.__name__} LOG] {message}")
    
    def _call_llm_with_fallback(self, messages: List, fallback_key: str = None) -> Dict[str, Any]:
        """ç»Ÿä¸€çš„LLMè°ƒç”¨å’Œé™çº§å¤„ç†"""
        try:
            response = self.llm.invoke(messages)
            content = response.content.strip()
            self._log(f"LLM Raw Response for {self.tool_type}: {content[:300]}...") # å¢åŠ æ—¥å¿—ï¼Œæ˜¾ç¤ºåŸå§‹å“åº”

            if not content:
                self._log(f"LLM returned empty content for {self.tool_type}.")
                raise ValueError("LLM returned empty content")

            result = json.loads(content)
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            if self.tool_type in self.config.REQUIRED_FIELDS:
                required = self.config.REQUIRED_FIELDS[self.tool_type]
                for field in required:
                    if field not in result:
                        # å¦‚æœå…³é”®å­—æ®µç¼ºå¤±ï¼Œä¹Ÿè§†ä¸ºä¸€ç§é”™è¯¯ï¼Œå¯èƒ½éœ€è¦é™çº§
                        self._log(f"Missing required field '{field}' in LLM response for {self.tool_type}.")
                        if fallback_key and fallback_key in self.config.FALLBACK_RESPONSES:
                            # å°è¯•ä»é™çº§å“åº”ä¸­å¡«å……ç¼ºå¤±å­—æ®µ
                            result[field] = self.config.FALLBACK_RESPONSES[fallback_key].get(
                                field, f"é»˜è®¤{field}å†…å®¹"
                            )
                        else:
                            result[field] = f"é»˜è®¤{field}å†…å®¹" 
            
            return result
            
        except json.JSONDecodeError as json_e:
            self._log(f"LLMè°ƒç”¨å¤±è´¥ (JSONDecodeError) for {self.tool_type}: {json_e}. Content was: {content[:300]}")
            if fallback_key and fallback_key in self.config.FALLBACK_RESPONSES:
                self._log(f"Using fallback response for {fallback_key}")
                return self.config.FALLBACK_RESPONSES[fallback_key].copy()
            return {} # è¿”å›ç©ºå­—å…¸ï¼Œè®©è°ƒç”¨æ–¹å¤„ç†
        except ValueError as val_e: # æ•è·ç©ºå†…å®¹é”™è¯¯
            self._log(f"LLMè°ƒç”¨å¤±è´¥ (ValueError) for {self.tool_type}: {val_e}.")
            if fallback_key and fallback_key in self.config.FALLBACK_RESPONSES:
                self._log(f"Using fallback response for {fallback_key}")
                return self.config.FALLBACK_RESPONSES[fallback_key].copy()
            return {}
        except Exception as e:
            self._log(f"LLMè°ƒç”¨å¤±è´¥ (General Exception) for {self.tool_type}: {e}")
            if fallback_key and fallback_key in self.config.FALLBACK_RESPONSES:
                self._log(f"Using fallback response for {fallback_key}")
                return self.config.FALLBACK_RESPONSES[fallback_key].copy()
            return {}
    
    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        return self.config.SYSTEM_PROMPTS.get(self.tool_type, "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¨¡æ‹Ÿå·¥å…·ã€‚")

# ğŸ¯ é‡æ„åçš„å·¥å…·ç±» - ä½¿ç”¨ç»§æ‰¿å‡å°‘é‡å¤

class PersonaGeneratorTool(BaseSimulationTool):
    """åŠŸèƒ½1: æŒ‡å®šäººæ•°å’Œéœ€æ±‚ï¼ŒæŒ‰ç…§éœ€æ±‚ç”Ÿæˆç”¨æˆ·æ¡£æ¡ˆ"""
    
    def __init__(self, llm: BaseChatModel, verbose: bool = False):
        super().__init__(llm, 'persona_generator', verbose)

    def execute(self, count: int, product_description: str, target_audience: str, requirements: str = "", **kwargs) -> List[UserPersona]:
        self._log(f"å¼€å§‹ç”Ÿæˆ {count} ä¸ªç”¨æˆ·ç”»åƒ...")

        user_prompt = f"""äº§å“æè¿°ï¼š{product_description}
ç›®æ ‡å—ä¼—ï¼š{target_audience}
éœ€æ±‚ç”¨æˆ·ä¸ªæ•°ï¼š{count}
{f"é¢å¤–è¦æ±‚ï¼š{requirements}" if requirements else ""}

è¯·ä»¥JSONæ•°ç»„æ ¼å¼è¾“å‡º{count}ä¸ªç”¨æˆ·ç”»åƒã€‚"""

        messages = [
            SystemMessage(content=self._get_system_prompt()),
            HumanMessage(content=user_prompt)
        ]

        try:
            response = self.llm.invoke(messages)
            content = response.content.strip()
            
            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
            self._log(f"LLMå“åº”å†…å®¹: {content[:200]}...")
            
            personas_data = json.loads(content) if content else []
            
            if not isinstance(personas_data, list):
                personas_data = [personas_data] if personas_data else []

            personas = []
            for i, data in enumerate(personas_data[:count]):
                try:
                    # éªŒè¯å¿…éœ€å­—æ®µ
                    for field in self.config.REQUIRED_FIELDS['persona']:
                        if field not in data:
                            raise ValueError(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                    
                    persona_id = str(uuid.uuid4())
                    persona = UserPersona(id=persona_id, **{k: v for k, v in data.items() if k != 'id'})
                    personas.append(persona)
                except Exception as e:
                    self._log(f"è§£æç”¨æˆ·ç”»åƒ {i} å¤±è´¥: {e}")
                    continue

            if not personas:
                personas = self._generate_fallback_personas(count, product_description)
            
            self._log(f"æˆåŠŸç”Ÿæˆ {len(personas)} ä¸ªç”¨æˆ·ç”»åƒ")
            return personas

        except Exception as e:
            self._log(f"ç”Ÿæˆç”¨æˆ·ç”»åƒå¤±è´¥: {e}")
            return self._generate_fallback_personas(count, product_description)

    def _generate_fallback_personas(self, count: int, product_desc: str) -> List[UserPersona]:
        """é™çº§ç”Ÿæˆç”¨æˆ·ç”»åƒ"""
        self._log(f"ä½¿ç”¨é™çº§æ¨¡å¼ç”Ÿæˆ {count} ä¸ªç”¨æˆ·ç”»åƒ")
        
        personas = []
        base_ages = [25, 30, 35, 40, 45]
        genders = ["ç”·æ€§", "å¥³æ€§"]
        
        for i in range(count):
            persona_id = str(uuid.uuid4())
            age = base_ages[i % len(base_ages)] + (i // len(base_ages)) * 3
            gender = genders[i % len(genders)]
            income_base = 80000 + i * 30000
            
            persona = UserPersona(
                id=persona_id,
                persona=f"ç”¨æˆ·{i+1}ï¼Œ{age}å²çš„{gender}ï¼Œå¯¹{product_desc}æ„Ÿå…´è¶£ã€‚",
                intent=f"å¯»æ‰¾èƒ½å¤Ÿè§£å†³å®é™…é—®é¢˜çš„{product_desc}äº§å“ï¼Œæå‡ç”Ÿæ´»æˆ–å·¥ä½œæ•ˆç‡",
                age=age,
                age_group=f"{age-5}-{age+5}",
                gender=gender,
                income=[income_base, income_base * 2],
                income_group=f"{income_base}-{income_base * 2}"
            )
            personas.append(persona)
        
        return personas

class ProductTrialSimulatorTool(BaseSimulationTool):
    """åŠŸèƒ½2: æœ‰äº§å“è¯¦æƒ…æ—¶ï¼Œæ¨¡æ‹Ÿç”¨æˆ·æ¡£æ¡ˆä½¿ç”¨äº§å“"""
    
    def __init__(self, llm: BaseChatModel, verbose: bool = False):
        super().__init__(llm, 'product_trial', verbose)

    def execute(self, user_persona: UserPersona, product_info: str, page_info: str, memory: List[str] = None, **kwargs) -> Dict[str, str]:
        self._log(f"æ¨¡æ‹Ÿç”¨æˆ· {user_persona.id} çš„äº§å“è¯•ç”¨...")

        memory_text = "; ".join(memory or [])
        user_prompt = f"""ç”¨æˆ·è§’è‰²ï¼š{user_persona.persona}
äº§å“ä¿¡æ¯ï¼š{product_info}
é¡µé¢ä¿¡æ¯ï¼š{page_info}
ç›¸å…³è®°å¿†ï¼š{memory_text}

è¯·æ¨¡æ‹Ÿè¯¥ç”¨æˆ·ä¸äº§å“çš„çœŸå®äº¤äº’è¿‡ç¨‹ï¼Œä½“ç°å…¶ä¸ªæ€§ç‰¹å¾å’Œå†³ç­–æ€è·¯ã€‚"""

        messages = [
            SystemMessage(content=self._get_system_prompt()),
            HumanMessage(content=user_prompt)
        ]

        result = self._call_llm_with_fallback(messages, 'product_trial')
        
        # å¦‚æœé™çº§å“åº”ï¼Œä¸ªæ€§åŒ–å¤„ç†
        if not result or result == self.config.FALLBACK_RESPONSES['product_trial']:
            result = {
                "å½“å‰çŠ¶æ€": f"æˆ‘æ­£åœ¨æµè§ˆ{page_info}ï¼Œäº†è§£äº§å“åŠŸèƒ½å’Œç‰¹ç‚¹",
                "æ€è€ƒè¿‡ç¨‹": f"ä½œä¸º{user_persona.age}å²çš„{user_persona.gender}ï¼Œæˆ‘éœ€è¦è¯„ä¼°è¿™ä¸ªäº§å“æ˜¯å¦ç¬¦åˆæˆ‘çš„éœ€æ±‚å’Œé¢„ç®—",
                "ä¸‹ä¸€æ­¥": "æ·±å…¥äº†è§£äº§å“çš„æ ¸å¿ƒåŠŸèƒ½å’Œä»·æ ¼ä¿¡æ¯"
            }

        return result

class MarketResearchTool(BaseSimulationTool):
    """åŠŸèƒ½3: æ— äº§å“è¯¦æƒ…æ—¶ï¼Œå¯¹ç”¨æˆ·åšå¸‚åœºè°ƒç ”"""
    
    def __init__(self, llm: BaseChatModel, verbose: bool = False):
        super().__init__(llm, 'market_research', verbose)

    def execute(self, user_persona: UserPersona, research_topics: List[str], **kwargs) -> Dict[str, str]:
        self._log(f"å¯¹ç”¨æˆ· {user_persona.id} è¿›è¡Œå¸‚åœºè°ƒç ”...")

        topics_text = "; ".join(research_topics)
        user_prompt = f"""ç”¨æˆ·ç”»åƒï¼š{user_persona.persona}
è°ƒç ”ä¸»é¢˜ï¼š{topics_text}

è¯·ä»è¿™ä¸ªç”¨æˆ·è§’è‰²çš„è§†è§’ï¼Œè¯¦ç»†åˆ†æå…¶åœ¨ç›¸å…³é¢†åŸŸçš„éœ€æ±‚ã€ç—›ç‚¹ã€åå¥½å’Œå†³ç­–å› ç´ ã€‚"""

        messages = [
            SystemMessage(content=self._get_system_prompt()),
            HumanMessage(content=user_prompt)
        ]

        result = self._call_llm_with_fallback(messages, 'market_research')
        
        # ä¸ªæ€§åŒ–é™çº§å“åº”
        if not result or len(result) < 3:
            result = {
                "needs": f"ä½œä¸º{user_persona.age}å²{user_persona.gender}ï¼Œæˆ‘éœ€è¦èƒ½æé«˜æ•ˆç‡å’Œä¾¿åˆ©æ€§çš„è§£å†³æ–¹æ¡ˆ",
                "pain_points": "ç°æœ‰å·¥å…·åŠŸèƒ½æœ‰é™ï¼Œä½¿ç”¨å¤æ‚ï¼Œå­¦ä¹ æˆæœ¬é«˜",
                "preferences": "ç•Œé¢ç®€æ´ç›´è§‚ï¼ŒåŠŸèƒ½å®ç”¨ï¼Œæ“ä½œç®€å•",
                "budget_considerations": f"æ ¹æ®{user_persona.income_group}æ”¶å…¥æ°´å¹³ï¼Œå¸Œæœ›ä»·æ ¼åˆç†ï¼Œæ€§ä»·æ¯”é«˜",
                "decision_factors": "å®ç”¨æ€§ã€æ˜“ç”¨æ€§ã€å“ç‰Œå£ç¢‘ã€å”®åæœåŠ¡",
                "usage_scenarios": "ä¸»è¦åœ¨å·¥ä½œå’Œç”Ÿæ´»ä¸­ä½¿ç”¨ï¼Œéœ€è¦é€‚åº”ä¸åŒåœºæ™¯éœ€æ±‚"
            }

        return result

class UserInterviewTool(BaseSimulationTool):
    """ç”¨æˆ·è®¿è°ˆå·¥å…· - æ”¶é›†å®šæ€§åé¦ˆ"""
    
    def __init__(self, llm: BaseChatModel, verbose: bool = False):
        super().__init__(llm, 'user_interview', verbose)

    def execute(self, user_persona: UserPersona, questions: List[str], behaviors: List[str] = None, satisfaction: int = 4, **kwargs) -> List[Dict[str, str]]:
        self._log(f"å¯¹ç”¨æˆ· {user_persona.id} è¿›è¡Œè®¿è°ˆ...")

        behavior_text = "; ".join(behaviors or [])
        responses = []
        
        for question in questions:
            user_prompt = f"""ç”¨æˆ·ç”»åƒï¼š{user_persona.persona}
è¡Œä¸ºå†å²ï¼š{behavior_text}
äº§å“ä½“éªŒæ€»ä½“æ»¡æ„åº¦ï¼š{satisfaction}/5åˆ†
è®¿è°ˆé—®é¢˜ï¼š{question}

è¯·çœŸå®è‡ªç„¶åœ°å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œä½“ç°ç”¨æˆ·çš„çœŸå®æ„Ÿå—å’Œä½“éªŒã€‚"""

            messages = [
                SystemMessage(content=self._get_system_prompt()),
                HumanMessage(content=user_prompt)
            ]

            result = self._call_llm_with_fallback(messages, 'user_interview')
            answer = result.get('answer', f"å¯¹äº'{question}'è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘è§‰å¾—äº§å“æ€»ä½“è¿˜ä¸é”™ã€‚")
            responses.append({'question': question, 'answer': answer})

        return responses

class UserInsightGeneratorTool(BaseSimulationTool): # ä¿®å¤ï¼šç»§æ‰¿ BaseSimulationTool
    """ç”¨æˆ·æ´å¯Ÿç”Ÿæˆå·¥å…· - åŸºäºç”¨æˆ·è¡Œä¸ºç”Ÿæˆäº§å“æ´å¯Ÿ"""
    
    def __init__(self, llm: BaseChatModel, verbose: bool = False):
        super().__init__(llm, 'insight_generator', verbose) # ä¿®å¤ï¼šè°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°

    def execute(self, user_persona: UserPersona, behaviors: List[str], **kwargs) -> List[str]:
        self._log(f"ä¸ºç”¨æˆ· {user_persona.id} ç”Ÿæˆæ´å¯Ÿ...") # ä½¿ç”¨ _log

        behavior_text = "; ".join(behaviors)

        user_prompt = f"""ä½ çš„è§’è‰²æè¿°æ˜¯ï¼š{user_persona.persona}

ä½ ä½¿ç”¨äº†ç½‘ç«™å¾—å‡ºäº†ä»¥ä¸‹è¡Œä¸ºï¼š{behavior_text}

è¯·æä¾›3-5ä¸ªå…·ä½“çš„æ´å¯Ÿï¼Œæ¯ä¸ªæ´å¯Ÿåº”è¯¥æ¸…æ™°ã€å…·ä½“ä¸”æœ‰ä»·å€¼ã€‚"""

        messages = [
            SystemMessage(content=self._get_system_prompt()), # ä½¿ç”¨ _get_system_prompt
            HumanMessage(content=user_prompt)
        ]

        # ä½¿ç”¨ç»Ÿä¸€çš„LLMè°ƒç”¨æ–¹æ³•
        result = self._call_llm_with_fallback(messages, fallback_key=None) # æ˜ç¡® fallback_key ä¸º Noneï¼Œå› ä¸ºæ²¡æœ‰é¢„è®¾çš„é™çº§
        
        insights = result.get('insights', [])

        # å¦‚æœLLMè°ƒç”¨å¤±è´¥ä¸”æ²¡æœ‰é™çº§ï¼Œæä¾›ä¸€ä¸ªé€šç”¨çš„é™çº§æ´å¯Ÿåˆ—è¡¨
        if not insights and not result: # æ£€æŸ¥ result æ˜¯å¦ä¸ºç©ºå­—å…¸ï¼Œè¡¨ç¤ºè°ƒç”¨å¤±è´¥ä¸”æ— é™çº§
            self._log(f"ç”Ÿæˆæ´å¯Ÿå¤±è´¥ï¼Œä½¿ç”¨é€šç”¨é™çº§æ´å¯Ÿ for {user_persona.id}")
            insights = [
                f"äº§å“ç•Œé¢è®¾è®¡ç¬¦åˆ{user_persona.age_group}å¹´é¾„æ®µç”¨æˆ·çš„ä½¿ç”¨ä¹ æƒ¯ã€‚",
                "åŠŸèƒ½å¸ƒå±€ç›¸å¯¹ç›´è§‚ï¼Œä½†ä»æœ‰ä¼˜åŒ–ç©ºé—´ã€‚",
                "ä»·æ ¼ç­–ç•¥éœ€è¦æ›´æ¸…æ™°çš„è¯´æ˜å’Œå¯¹æ¯”ã€‚"
            ]
        elif not insights and 'insights' not in result: # å¦‚æœ LLM å“åº”äº†ä½†æ²¡æœ‰ insights å­—æ®µ
             self._log(f"LLM å“åº”ä¸­ç¼ºå°‘ 'insights' å­—æ®µï¼Œä½¿ç”¨é€šç”¨é™çº§æ´å¯Ÿ for {user_persona.id}")
             insights = [
                f"ç”¨æˆ· {user_persona.gender} ({user_persona.age}å²) å¯¹äº§å“è¡¨ç°å‡ºåˆæ­¥å…´è¶£ã€‚",
                "éœ€è¦è¿›ä¸€æ­¥åˆ†æç”¨æˆ·è¡Œä¸ºä»¥è·å–æ›´æ·±å±‚æ¬¡çš„æ´å¯Ÿã€‚",
            ]


        return insights

class UserSimulationStatsTool:
    """åŠŸèƒ½4: ç”¨æˆ·è¡Œä¸ºä¿¡æ¯å’Œè´¨æ€§ä¿¡æ¯è¾“å‡º/ç»Ÿè®¡"""
    
    def __init__(self, verbose: bool = False):
        self.verbose = verbose

    def execute(self, personas: List[UserPersona], records: List[SimulationRecord], **kwargs) -> Dict[str, Any]:
        if self.verbose:
            print("[UserSimulationStatsTool LOG] ç”Ÿæˆç»Ÿè®¡åˆ†æ...")
        
        if not personas:
            return {"message": "æš‚æ— æ•°æ®", "timestamp": datetime.now().isoformat()}

        # äººå£ç»Ÿè®¡å­¦åˆ†æ
        ages = [p.age for p in personas]
        genders = [p.gender for p in personas]
        income_groups = [p.income_group for p in personas]

        # è¡Œä¸ºç»Ÿè®¡åˆ†æ
        action_counts = {}
        for record in records:
            action_counts[record.action_type] = action_counts.get(record.action_type, 0) + 1

        # æ»¡æ„åº¦ç»Ÿè®¡
        satisfactions = []
        insights_all = []
        for record in records:
            if record.action_type == 'interview' and 'satisfaction' in record.data:
                satisfactions.append(record.data['satisfaction'])
            elif record.action_type == 'insight' and 'insights' in record.data:
                insights_all.extend(record.data['insights'])

        return {
            "ç”¨æˆ·æ€»æ•°": len(personas),
            "äººå£ç»Ÿè®¡å­¦åˆ†æ": {
                "å¹³å‡å¹´é¾„": round(sum(ages) / len(ages), 1),
                "å¹´é¾„èŒƒå›´": f"{min(ages)}-{max(ages)}å²",
                "æ€§åˆ«åˆ†å¸ƒ": {g: genders.count(g) for g in set(genders)},
                "æ”¶å…¥åˆ†å¸ƒ": {ig: income_groups.count(ig) for ig in set(income_groups)}
            },
            "è¡Œä¸ºç»Ÿè®¡åˆ†æ": {
                "æ€»è®°å½•æ•°": len(records),
                "è¡Œä¸ºç±»å‹åˆ†å¸ƒ": action_counts,
                "ç”¨æˆ·å¹³å‡æ´»è·ƒåº¦": round(len(records) / len(personas), 1) if personas else 0
            },
            "è´¨æ€§ä¿¡æ¯åˆ†æ": {
                "å¹³å‡æ»¡æ„åº¦": round(sum(satisfactions) / len(satisfactions), 1) if satisfactions else None,
                "æ»¡æ„åº¦åˆ†å¸ƒ": {str(s): satisfactions.count(s) for s in set(satisfactions)} if satisfactions else {},
                "æ€»æ´å¯Ÿæ•°é‡": len(insights_all),
                "æ´å¯Ÿæ ·æœ¬": insights_all[:5] if insights_all else []
            },
            "ç»Ÿè®¡æ—¶é—´": datetime.now().isoformat()
        }

class UserSimulationSuite:
    """ç”¨æˆ·æ¨¡æ‹Ÿå·¥å…·å¥—ä»¶ - æ•´åˆæ‰€æœ‰åŠŸèƒ½çš„ä¸»æ§åˆ¶å™¨"""
    
    def __init__(self, llm: BaseChatModel, verbose: bool = False):
        self.llm = llm
        self.verbose = verbose
        
        # åˆå§‹åŒ–å„ä¸ªå·¥å…·
        self.persona_generator = PersonaGeneratorTool(llm, verbose)
        self.trial_simulator = ProductTrialSimulatorTool(llm, verbose)
        self.market_researcher = MarketResearchTool(llm, verbose)
        self.interviewer = UserInterviewTool(llm, verbose)
        self.insight_generator = UserInsightGeneratorTool(llm, verbose)
        self.stats_tool = UserSimulationStatsTool(verbose)
        
        # æ•°æ®å­˜å‚¨
        self.personas: Dict[str, UserPersona] = {}
        self.records: List[SimulationRecord] = []

    def _record_action(self, user_id: str, action_type: str, data: Dict[str, Any]):
        """è®°å½•ç”¨æˆ·è¡Œä¸º"""
        record = SimulationRecord(
            user_id=user_id,
            timestamp=datetime.now().isoformat(),
            action_type=action_type,
            data=data
        )
        self.records.append(record)
        if self.verbose:
            print(f"è®°å½•ç”¨æˆ·è¡Œä¸º: {action_type} for {user_id}")

    def generate_personas(self, count: int, product_description: str, target_audience: str, requirements: str = "") -> List[UserPersona]:
        """ç”Ÿæˆç”¨æˆ·ç”»åƒ"""
        personas = self.persona_generator.execute(count, product_description, target_audience, requirements)
        
        for persona in personas:
            self.personas[persona.id] = persona
            self._record_action(persona.id, 'persona', asdict(persona))
        
        return personas

    def simulate_product_trial(self, user_id: str, product_info: str, page_info: str, memory: List[str] = None) -> Dict[str, str]:
        """æ¨¡æ‹Ÿäº§å“è¯•ç”¨"""
        if user_id not in self.personas:
            raise ValueError(f"User {user_id} not found")
        
        result = self.trial_simulator.execute(self.personas[user_id], product_info, page_info, memory)
        self._record_action(user_id, 'trial', result)
        return result

    def conduct_market_research(self, user_id: str, research_topics: List[str]) -> Dict[str, str]:
        """è¿›è¡Œå¸‚åœºè°ƒç ”"""
        if user_id not in self.personas:
            raise ValueError(f"User {user_id} not found")
        
        result = self.market_researcher.execute(self.personas[user_id], research_topics)
        self._record_action(user_id, 'research', result)
        return result

    def conduct_interview(self, user_id: str, questions: List[str], behaviors: List[str] = None, satisfaction: int = 4) -> List[Dict[str, str]]:
        """è¿›è¡Œç”¨æˆ·è®¿è°ˆ"""
        if user_id not in self.personas:
            raise ValueError(f"User {user_id} not found")
        
        result = self.interviewer.execute(self.personas[user_id], questions, behaviors, satisfaction)
        self._record_action(user_id, 'interview', {'responses': result, 'satisfaction': satisfaction})
        return result

    def generate_insights(self, user_id: str, behaviors: List[str]) -> List[str]:
        """ç”Ÿæˆç”¨æˆ·æ´å¯Ÿ"""
        if user_id not in self.personas:
            raise ValueError(f"User {user_id} not found")
        
        result = self.insight_generator.execute(self.personas[user_id], behaviors)
        self._record_action(user_id, 'insight', {'insights': result})
        return result

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡åˆ†æ"""
        return self.stats_tool.execute(list(self.personas.values()), self.records)

    def export_data(self, format: str = "json") -> str:
        """å¯¼å‡ºå®Œæ•´æ•°æ®"""
        if self.verbose:
            print(f"å¯¼å‡ºæ•°æ®ï¼Œæ ¼å¼: {format}")
        
        export_data = {
            "ç”¨æˆ·ç”»åƒ": [asdict(p) for p in self.personas.values()],
            "æ¨¡æ‹Ÿè®°å½•": [asdict(r) for r in self.records],
            "ç»Ÿè®¡åˆ†æ": self.get_statistics(),
            "å¯¼å‡ºæ—¶é—´": datetime.now().isoformat()
        }

        if format.lower() == "json":
            return json.dumps(export_data, ensure_ascii=False, indent=2)
        else:
            # CSVæ ¼å¼ç®€åŒ–è¾“å‡º
            csv_lines = ["# ç”¨æˆ·æ¨¡æ‹Ÿæ•°æ®å¯¼å‡º"]
            csv_lines.append("ç”¨æˆ·ID,å¹´é¾„,æ€§åˆ«,æ”¶å…¥ç»„åˆ«,æ„å›¾,è®°å½•æ•°")

            for persona in self.personas.values():
                record_count = sum(1 for r in self.records if r.user_id == persona.id)
                csv_lines.append(f"{persona.id},{persona.age},{persona.gender},{persona.income_group},{persona.intent},{record_count}")

            return "\n".join(csv_lines)

# LangChainå·¥å…·æ¥å£
@tool
def generate_user_personas_tool(count: int, product_description: str, target_audience: str, requirements: str = "") -> str:
    """ç”Ÿæˆç”¨æˆ·ç”»åƒå·¥å…·"""
    return f"ç”Ÿæˆç”¨æˆ·ç”»åƒå·¥å…·: éœ€è¦ {count} ä¸ªç”¨æˆ·ï¼Œäº§å“: {product_description}ï¼Œç›®æ ‡: {target_audience}"

@tool 
def simulate_product_trial_tool(user_persona_json: str, product_info: str, page_info: str, memory: str = "") -> str:
    """æ¨¡æ‹Ÿäº§å“è¯•ç”¨å·¥å…·"""
    return f"äº§å“è¯•ç”¨æ¨¡æ‹Ÿ: ç”¨æˆ·åœ¨ {page_info} è¯•ç”¨ {product_info}"

@tool
def conduct_user_interview_tool(user_persona_json: str, questions: str, behaviors: str = "", satisfaction: int = 4) -> str:
    """ç”¨æˆ·è®¿è°ˆå·¥å…·"""
    return f"ç”¨æˆ·è®¿è°ˆ: æ»¡æ„åº¦ {satisfaction}/5ï¼Œé—®é¢˜: {questions.split(';')[0]}..."

@tool
def market_research_analysis_tool(user_persona_json: str, research_topics: str) -> str:
    """å¸‚åœºè°ƒç ”å·¥å…·"""
    return f"å¸‚åœºè°ƒç ”: ä¸»é¢˜ {research_topics.split(';')[0]}..."

# ç®€å•æµ‹è¯•å’Œæ¼”ç¤ºä»£ç 
if __name__ == "__main__":
    print("ğŸ§ª UserSimulation å·¥å…·å¥—ä»¶åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ é”™è¯¯: OPENAI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        print("è¯·ç¡®ä¿ .env æ–‡ä»¶ä¸­è®¾ç½®äº†æ­£ç¡®çš„ API å¯†é’¥")
        print("=" * 60)
        exit(1)
    
    print("âœ… ç¯å¢ƒå˜é‡æ£€æŸ¥é€šè¿‡")
    print("âœ… å·¥å…·å¥—ä»¶å®šä¹‰å®Œæˆï¼ŒåŒ…å«ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š")
    print("1. PersonaGeneratorTool - ç”Ÿæˆç”¨æˆ·ç”»åƒ")
    print("2. ProductTrialSimulatorTool - æ¨¡æ‹Ÿäº§å“è¯•ç”¨")
    print("3. MarketResearchTool - å¸‚åœºè°ƒç ”åˆ†æ")
    print("4. UserInterviewTool - ç”¨æˆ·è®¿è°ˆ")
    print("5. UserInsightGeneratorTool - æ´å¯Ÿç”Ÿæˆ")
    print("6. UserSimulationStatsTool - æ•°æ®ç»Ÿè®¡åˆ†æ")
    print("7. UserSimulationSuite - ä¸»æ§åˆ¶å™¨")
    
    try:
        from langchain_openai import ChatOpenAI

        # ğŸ¯ ä¿®å¤ï¼šæ­£ç¡®é…ç½®LLM
        llm = ChatOpenAI(
            model="gpt-4o",
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_API_BASE"),
            temperature=0.8  # <--- åœ¨è¿™é‡Œè°ƒæ•´æ¸©åº¦ï¼Œä¾‹å¦‚è®¾ç½®ä¸º 0.8 ä»¥å¢åŠ å·®å¼‚æ€§
        )
        
        print("\nğŸ¯ å¼€å§‹å®é™…æµ‹è¯•...")
        suite = UserSimulationSuite(llm=llm, verbose=True)

        # 1. ç”Ÿæˆç”¨æˆ·ç”»åƒ
        print("\n1. æµ‹è¯•ç”Ÿæˆç”¨æˆ·ç”»åƒ...")
        personas = suite.generate_personas(2, "å•†ä¸šå†³ç­–æ¨¡æ‹Ÿå¹³å°", "åˆ›ä¸šè€…å’Œä¸­å°ä¼ä¸šä¸»", "éœ€è¦å¤šæ ·åŒ–çš„ç”¨æˆ·ç”»åƒï¼Œæ¶µç›–ä¸åŒå¹´é¾„ã€æ€§åˆ«å’Œæ”¶å…¥æ°´å¹³ï¼Œæ— æ­§è§†ã€‚")
        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(personas)} ä¸ªç”¨æˆ·ç”»åƒ")
        print(personas)

        # ä¿®æ”¹æµ‹è¯•éƒ¨åˆ† - å¯¹æ‰€æœ‰ç”¨æˆ·è¿›è¡Œå…¨é¢æµ‹è¯•
        if personas:
            print(f"\nğŸ¯ å¼€å§‹å¯¹ {len(personas)} ä¸ªç”¨æˆ·è¿›è¡Œå…¨é¢æµ‹è¯•...")
            
            # 2. ä¸ºæ¯ä¸ªç”¨æˆ·æ¨¡æ‹Ÿäº§å“è¯•ç”¨
            print("\n2. æµ‹è¯•äº§å“è¯•ç”¨æ¨¡æ‹Ÿ...")
            for i, persona in enumerate(personas):
                print(f"\n   ğŸ‘¤ ç”¨æˆ· {i+1}: {persona.persona[:80]}...")
                print(f"   åŸºæœ¬ä¿¡æ¯: {persona.age}å²{persona.gender}, æ”¶å…¥: {persona.income_group}")
                
                trial_result = suite.simulate_product_trial(
                    persona.id, 
                    "AIé©±åŠ¨çš„å•†ä¸šå†³ç­–æ¨¡æ‹Ÿå¹³å°ï¼Œé€šè¿‡ç”¨æˆ·è¡Œä¸ºæ¨¡æ‹Ÿå’Œå¸‚åœºååº”æ¨æ¼”ï¼Œé‡åŒ–é£é™©ä¸æ”¶ç›Šï¼Œå¸®åŠ©å®¢æˆ·åœ¨å®æ–½å‰é¢„åˆ¤å†³ç­–æ•ˆæœï¼Œé™ä½è¯•é”™æˆæœ¬ã€‚", 
                    "äº§å“ä¸»é¡µ - åŠŸèƒ½ä»‹ç»ç•Œé¢",
                    [f"è®¿é—®äº†äº§å“å®˜ç½‘", f"æµè§ˆäº†åŠŸèƒ½ä»‹ç»", f"æŸ¥çœ‹äº†ä»·æ ¼ä¿¡æ¯"]
                )
                print(f"   âœ… è¯•ç”¨æ¨¡æ‹Ÿå®Œæˆ")
                print(f"   å½“å‰çŠ¶æ€: {trial_result['å½“å‰çŠ¶æ€']}")
                print(f"   æ€è€ƒè¿‡ç¨‹: {trial_result['æ€è€ƒè¿‡ç¨‹']}")
                print(f"   ä¸‹ä¸€æ­¥: {trial_result['ä¸‹ä¸€æ­¥']}")

            # 3. ä¸ºæ¯ä¸ªç”¨æˆ·è¿›è¡Œå¸‚åœºè°ƒç ”
            print("\n3. æµ‹è¯•å¸‚åœºè°ƒç ”...")
            research_topics = ["éœ€æ±‚æƒ…å†µ", "é•¿æœŸä½¿ç”¨æ„æ„¿/å¿…è¦æ€§", "ç—›ç‚¹å’Œåå¥½", "ä»˜è´¹æ„æ„¿", "å†³ç­–å› ç´ ", "ä½¿ç”¨åœºæ™¯"]
            for i, persona in enumerate(personas):
                print(f"\n   ğŸ‘¤ ç”¨æˆ· {i+1} å¸‚åœºè°ƒç ”:")
                research_result = suite.conduct_market_research(
                    persona.id,
                    research_topics
                )
                print(f"   âœ… è°ƒç ”å®Œæˆ")
                print(f"   éœ€æ±‚: {research_result['needs'][:60]}...")
                print(f"   ç—›ç‚¹: {research_result['pain_points'][:60]}...")
                print(f"   åå¥½: {research_result['preferences'][:60]}...")
                print(f"   é¢„ç®—è€ƒè™‘: {research_result['budget_considerations'][:60]}...")

            # 4. ä¸ºæ¯ä¸ªç”¨æˆ·è¿›è¡Œè®¿è°ˆ
            print("\n4. æµ‹è¯•ç”¨æˆ·è®¿è°ˆ...")
            questions = [
                "æ‚¨è§‰å¾—æœ€é‡è¦çš„äº§å“åŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ",
                "å¦‚æœä¸€å®šè¦åšMVPï¼Œæ‚¨è®¤ä¸ºå“ªäº›åŠŸèƒ½æ˜¯å¿…é¡»çš„ï¼Ÿ",
            ]
            
            for i, persona in enumerate(personas):
                print(f"\n   ğŸ‘¤ ç”¨æˆ· {i+1} è®¿è°ˆ:")
                satisfaction_score = 4 + (i % 2)  # ä¸åŒç”¨æˆ·ä¸åŒæ»¡æ„åº¦ (4æˆ–5)
                
                interview_result = suite.conduct_interview(
                    persona.id,
                    questions,
                    ["è¯•ç”¨äº†äº§å“æ ¸å¿ƒåŠŸèƒ½", "ä½“éªŒäº†å†³ç­–æ¨¡æ‹Ÿ", "æŸ¥çœ‹äº†æ¡ˆä¾‹åˆ†æ"],
                    satisfaction=satisfaction_score
                )
                
                print(f"   âœ… è®¿è°ˆå®Œæˆ: {len(interview_result)} ä¸ªé—®é¢˜ï¼Œæ»¡æ„åº¦: {satisfaction_score}/5")
                for j, response in enumerate(interview_result):
                    print(f"   é—®é¢˜{j+1}: {response['question']}")
                    print(f"   å›ç­”: {response['answer'][:100]}...")
                    print("   " + "-" * 50)

            # 5. ä¸ºæ¯ä¸ªç”¨æˆ·ç”Ÿæˆæ´å¯Ÿ
            print("\n5. æµ‹è¯•æ´å¯Ÿç”Ÿæˆ...")
            for i, persona in enumerate(personas):
                print(f"\n   ğŸ‘¤ ç”¨æˆ· {i+1} æ´å¯Ÿç”Ÿæˆ:")
                
                # æ ¹æ®ç”¨æˆ·ç‰¹å¾å®šåˆ¶è¡Œä¸ºå†å²
                behaviors = [
                    f"ä½œä¸º{persona.age}å²{persona.gender}ï¼Œé¦–æ¬¡è®¿é—®äº†äº§å“ä¸»é¡µ",
                    "è¯¦ç»†äº†è§£äº†AIå†³ç­–æ¨¡æ‹ŸåŠŸèƒ½",
                    "æŸ¥çœ‹äº†ä¸åŒè¡Œä¸šçš„åº”ç”¨æ¡ˆä¾‹",
                ]
                
                insights = suite.generate_insights(persona.id, behaviors)
                print(f"   âœ… ç”Ÿæˆ {len(insights)} æ¡æ´å¯Ÿ")
                for j, insight in enumerate(insights):
                    print(f"   æ´å¯Ÿ{j+1}: {insight}")

            # 6. è·å–ç»¼åˆç»Ÿè®¡åˆ†æ
            print("\n6. æµ‹è¯•ç»Ÿè®¡åˆ†æ...")
            stats = suite.get_statistics()
            print("=" * 60)
            print("ğŸ“Š ç»¼åˆç»Ÿè®¡åˆ†æç»“æœ")
            print("=" * 60)
            
            print(f"âœ… ç”¨æˆ·æ€»æ•°: {stats['ç”¨æˆ·æ€»æ•°']}")
            print(f"âœ… æ€»è®°å½•æ•°: {stats['è¡Œä¸ºç»Ÿè®¡åˆ†æ']['æ€»è®°å½•æ•°']}")
            
            print("\nğŸ‘¥ äººå£ç»Ÿè®¡å­¦åˆ†æ:")
            demo_stats = stats['äººå£ç»Ÿè®¡å­¦åˆ†æ']
            print(f"   å¹³å‡å¹´é¾„: {demo_stats['å¹³å‡å¹´é¾„']}å²")
            print(f"   å¹´é¾„èŒƒå›´: {demo_stats['å¹´é¾„èŒƒå›´']}")
            print(f"   æ€§åˆ«åˆ†å¸ƒ: {demo_stats['æ€§åˆ«åˆ†å¸ƒ']}")
            print(f"   æ”¶å…¥åˆ†å¸ƒ: {demo_stats['æ”¶å…¥åˆ†å¸ƒ']}")
            
            print("\nğŸ“ˆ è¡Œä¸ºç»Ÿè®¡åˆ†æ:")
            behavior_stats = stats['è¡Œä¸ºç»Ÿè®¡åˆ†æ']
            print(f"   è¡Œä¸ºç±»å‹åˆ†å¸ƒ: {behavior_stats['è¡Œä¸ºç±»å‹åˆ†å¸ƒ']}")
            print(f"   ç”¨æˆ·å¹³å‡æ´»è·ƒåº¦: {behavior_stats['ç”¨æˆ·å¹³å‡æ´»è·ƒåº¦']}")
            
            print("\nğŸ’¬ è´¨æ€§ä¿¡æ¯åˆ†æ:")
            # quality_stats = stats['è´¨æ€§ä¿¡æ¯'] # æ—§çš„é”™è¯¯ä»£ç 
            quality_stats = stats['è´¨æ€§ä¿¡æ¯åˆ†æ'] # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„é”®å
            if quality_stats.get('å¹³å‡æ»¡æ„åº¦') is not None: # ä¿®å¤ï¼šæ›´å®‰å…¨çš„æ£€æŸ¥æ–¹å¼
                print(f"   å¹³å‡æ»¡æ„åº¦: {quality_stats['å¹³å‡æ»¡æ„åº¦']}/5")
                print(f"   æ»¡æ„åº¦åˆ†å¸ƒ: {quality_stats['æ»¡æ„åº¦åˆ†å¸ƒ']}")
            else:
                print(f"   å¹³å‡æ»¡æ„åº¦: N/A") # å¦‚æœæ²¡æœ‰æ»¡æ„åº¦æ•°æ®

            print(f"   æ€»æ´å¯Ÿæ•°é‡: {quality_stats['æ€»æ´å¯Ÿæ•°é‡']}")
            
            if quality_stats['æ´å¯Ÿæ ·æœ¬']:
                print("   æ´å¯Ÿæ ·æœ¬:")
                for insight in quality_stats['æ´å¯Ÿæ ·æœ¬']:
                    print(f"     â€¢ {insight}")
            else:
                print("   æ´å¯Ÿæ ·æœ¬: N/A")


            # 7. å¯¼å‡ºæ•°æ®æµ‹è¯•
            print("\n7. æµ‹è¯•æ•°æ®å¯¼å‡º...")
            json_export = suite.export_data("json")
            csv_export = suite.export_data("csv")
            
            print(f"âœ… JSONå¯¼å‡ºå®Œæˆ: {len(json_export)} å­—ç¬¦")
            print(f"âœ… CSVå¯¼å‡ºå®Œæˆ: {len(csv_export.split('//n'))} è¡Œ")  # ä¿®å¤ï¼šä½¿ç”¨å•ä¸ªåæ–œæ 
            
            # ä¿å­˜å¯¼å‡ºæ–‡ä»¶
            with open("user_simulation_export.json", "w", encoding="utf-8") as f:
                f.write(json_export)
            
            with open("user_simulation_export.csv", "w", encoding="utf-8") as f:
                f.write(csv_export)
            
            print("âœ… å¯¼å‡ºæ–‡ä»¶å·²ä¿å­˜: user_simulation_export.json, user_simulation_export.csv")

            print("\n" + "=" * 60)
            print("ğŸ‰ æ‰€æœ‰åŠŸèƒ½å…¨é¢æµ‹è¯•å®Œæˆï¼")
            print("=" * 60)
            print(f"ğŸ“‹ æµ‹è¯•æ€»ç»“:")
            print(f"   â€¢ ç”Ÿæˆç”¨æˆ·: {stats['ç”¨æˆ·æ€»æ•°']} ä¸ª")
            print(f"   â€¢ æ¨¡æ‹Ÿè¯•ç”¨: {stats['ç”¨æˆ·æ€»æ•°']} æ¬¡")
            print(f"   â€¢ å¸‚åœºè°ƒç ”: {stats['ç”¨æˆ·æ€»æ•°']} æ¬¡") 
            print(f"   â€¢ ç”¨æˆ·è®¿è°ˆ: {stats['ç”¨æˆ·æ€»æ•°']} æ¬¡ (æ¯æ¬¡{len(questions)}ä¸ªé—®é¢˜)")
            print(f"   â€¢ æ´å¯Ÿç”Ÿæˆ: {stats['ç”¨æˆ·æ€»æ•°']} æ¬¡")
            print(f"   â€¢ æ€»è¡Œä¸ºè®°å½•: {stats['è¡Œä¸ºç»Ÿè®¡åˆ†æ']['æ€»è®°å½•æ•°']} æ¡")
            print(f"   â€¢ å¹³å‡æ»¡æ„åº¦: {quality_stats.get('å¹³å‡æ»¡æ„åº¦', 'N/A')}/5")
            
            # 8. å±•ç¤ºç”¨æˆ·ç”»åƒæ‘˜è¦
            print(f"\nğŸ‘¥ ç”¨æˆ·ç”»åƒæ‘˜è¦:")
            for i, persona in enumerate(personas):
                print(f"   ç”¨æˆ·{i+1}: {persona.age}å²{persona.gender}, {persona.income_group}, æ„å›¾: {persona.intent[:50]}...")
            
            print("\nğŸš€ ç”¨æˆ·æ¨¡æ‹Ÿç³»ç»Ÿæµ‹è¯•æˆåŠŸå®Œæˆï¼")

        else:
            print("âŒ æ²¡æœ‰ç”Ÿæˆä»»ä½•ç”¨æˆ·ç”»åƒï¼Œæµ‹è¯•æ— æ³•ç»§ç»­")
    
    except ImportError:
        print("âš ï¸ æ— æ³•å¯¼å…¥ langchain_openaiï¼Œè·³è¿‡å®é™…æµ‹è¯•")
        print("è¯·ç¡®ä¿å·²å®‰è£…: pip install langchain-openai")
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
    
    print("\n" + "=" * 60)